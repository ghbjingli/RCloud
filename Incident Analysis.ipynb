{"cells":[{"cell_type":"markdown","metadata":{},"source":["### This work is the EDA part for incidents analytics work\n- The dataset are downloaded from SSR report. This one is the incidents dataset"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# import required labraries\nimport pandas as pd \nimport numpy as np\n\n# Read in incident data from excel sheet. This data set is downloaded from SSR report\ndf = pd.read_csv(\"/opt/data/share01/jl2408/2018incidents.csv\")\n# list column names\ncln = list(df)\nprint(cln)\ns_cln = ['INCIDENT_TICKET_NUMBER', 'ROOT_CAUSE', 'SUB_CAUSE', 'PBLM_CAUSED_BY_CHANGE', 'OUTAGE_CAUSER', 'START_DATE', 'START_TIME', 'END_DATE', 'END_TIME', 'INCIDENT_DURATION', 'ALERTED', 'SEVERITY_CLASS', 'DOWNTIME_TYPE', 'SERVICE_COMPONENT', 'AVP_ATTUID', 'AVP_NAME', 'VP_ATTUID', 'VP_NAME', 'SVP_ATTUID', 'SVP_NAME', 'COE_NAME', 'COE_ORG', 'RCO_SVP_VP', 'IMPACTED_APPS']\nid_cln = s_cln[:]\nid_cln.remove('IMPACTED_APPS')\ns_cln2 = ['INCIDENT_TICKET_NUMBER', 'ROOT_CAUSE', 'SUB_CAUSE', 'PBLM_CAUSED_BY_CHANGE', 'OUTAGE_CAUSER', 'START_DATE', 'START_TIME', 'END_DATE', 'END_TIME', 'INCIDENT_DURATION', 'ALERTED', 'SEVERITY_CLASS', 'DOWNTIME_TYPE', 'SERVICE_COMPONENT', 'IMPACTED_APPS']\nprint(id_cln)\n# Example data in train\ndf.head()"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Data information in train\ndf.info()"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Get a subset of the data\ndf = df[s_cln]"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# Number of unique values\ndf.apply(pd.Series.nunique)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# Check for missing values\nprint(df.isnull().sum())"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# data set info\ndf.info()"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# remove duplicated rows\ndf1 = df.drop_duplicates()\ndf1.info()"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# check unique values in ROOT_CAUSE\ndf1.ROOT_CAUSE.unique()"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# check unique values in SUB_CAUSE\ndf1.SUB_CAUSE.unique()"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Inconsistent content in IMPACTED_APPS\n# For example, we see multiple impacted applications in ticket 253909391-1\n\ndf1[[\"INCIDENT_TICKET_NUMBER\",\"IMPACTED_APPS\"]]"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# Check multi-impacted-apps from IMPACTED_APPS\nimport re\nm_apps = df1[\"IMPACTED_APPS\"].apply(lambda x: re.findall(\"[^,]+,+[^,]+,+[^,]+\",str(x)))\nm_apps[m_apps.str.len() != 0].head(10)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# We need to split these into multiple rows in order to get correct and consistent impacted application metrics\ndf2= df1[\"IMPACTED_APPS\"].str.split(\",\",expand = True) \\\n.merge(df1, right_index = True, left_index = True) \\\n.drop([\"IMPACTED_APPS\"], axis = 1)\ndf2 = pd.melt(df2, id_vars = id_cln, value_name = \"IMPACTED_APPS\")\ndf2 = df2.drop(\"variable\", axis = 1)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["pd.__version__"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["# data set info\ndf2.info()"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# a log of none value created in IMPACTED_APPS\ndf2.isnull().sum()"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["# drop rows associated with these None IMPACTED_APPS\nimport numpy as np\ndf2 = df2[pd.notnull(df2['IMPACTED_APPS'])]"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["# a log of none value created in IMPACTED_APPS\ndf2.isnull().sum()"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["# drop duplicate rows\ndf2.drop_duplicates(inplace=True)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["# a log of none value created in IMPACTED_APPS\ndf2.isnull().sum()"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["df2.info()"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["df2.to_excel(\"/opt/data/share01/jl2408/tmp.xlsx\")"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["df3 = pd.read_excel(\"/opt/data/share01/jl2408/tmp.xlsx\")"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["df3.drop_duplicates(inplace=True)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["df3.info()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.1"}},"nbformat":4,"nbformat_minor":2}
