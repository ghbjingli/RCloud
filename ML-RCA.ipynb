{"cells":[{"cell_type":"markdown","metadata":{},"source":["### CPR Tech Sharing - Jing Li - 04/26/2018\n### Demo the use of Naive Bayes classifier with oversimplified RCA (Naive Bayes is a family of ML algorithms for supervised learning)\n\n- Problem statement: we have a set of data containing CPU and Memory utilization statistics and server status (good or bad at that point). We want to use machine learning to predict the server status at a future observation of CPU and Memory statistics\n- X contains variables (features): an array containing pairs of CPU and Memory utilization statistics in percentage.\n- Y contains corresponding class labels: an array containing server status. \n- For example, the first data point has 'Good' corresponds to when CPU utilization is 40% and memory utilization is 80%. The 4th data point has CPU utilization 99% and memory utilization 20% with 'Bad' label\n- So, X and Y are the stats we collected over time. We want to use machine learning to predict/classify the server status (Y) based on server key performance indicators (X).\n- We pick up a machine learning algorithm (Model) called Gaussian Naive Bayes and we will train the model to learn based on past experience using the collected data.\n- We will then use the trained model to predict/classify the server status with a new observation of key performance indiicator.\n- in the first example, we predict that server status is 'Good' when we have CPU utilization = 47% and memory utilization = 82% \nin the second example, we predict that server status is 'bad' when we have CPU utilization = 95% and memory utilization = 20% \n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# load numpy library\nimport numpy as np\n# construct training data set\nX = np.array([[40, 80], [50, 85], [45, 84], [99, 20], [50, 80], [55, 83], [40, 81], [53, 85], [46, 84], [95, 25], [51, 87], [52, 80]])\n# Y = np.array(['Good', 'Good', 'Good', 'Bad', 'Good', 'Good', 'Good', 'Good', 'Good', 'Bad', 'Good', 'Good'])\nY = np.array([0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0])\n\n# load Naive Bayes \nfrom sklearn.naive_bayes import GaussianNB\n\n# Create a model\nclf = GaussianNB()\n\n# Traing the model with data set\nclf.fit(X, Y)\n\n# Print model accuracy\nprint \"Model accuracy is \" + str(clf.score(X,Y))\n\n# Create a new observation of X\nnewX1 = [[47,82]]\n\n# Predict server status with CPU and Memory statistics\nnewY1 = clf.predict(newX1)\n\n# Create a new observation of X\nnewX2 = [[60,20]]\n\n# Predict server status with CPU and Memory statistics\nnewY2 = clf.predict(newX2)\n\n# Print out the prediction\nprint \"Naive Bayes predict the server status with CPU at \" + str(newX1[0][0]) + \"% and Memory at \" + str(newX1[0][1]) + \"% utilization is \" +  str(newY1[0])\nprint \"Naive Bayes predict The server status with CPU at \" + str(newX2[0][0]) + \"% and Memory at \" + str(newX2[0][1]) + \"% utilization is \" +  str(newY2[0])\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["### draw the decision boundary with the test points overlaid\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nx_min = 0.0; x_max = 100.0\ny_min = 0.0; y_max = 100.0\n\n# Plot the decision boundary. For that, we will assign a color to each\n# point in the mesh [x_min, m_max]x[y_min, y_max].\nh = .1  # step size in the mesh\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\nZ = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n\n# the training data (features_train, labels_train) have both \"Good\" and \"Bad\" points mixed\n# in together--separate them so we can give them different colors in the scatterplot,\n# and visually identify them\ncpu_good = [X[ii][0] for ii in range(0, len(X)) if Y[ii]==0]\nmem_good = [X[ii][1] for ii in range(0, len(X)) if Y[ii]==0]\ncpu_bad = [X[ii][0] for ii in range(0, len(X)) if Y[ii]==1]\nmem_bad = [X[ii][1] for ii in range(0, len(X)) if Y[ii]==1]\n\n# Plot also the test points\ncpu_good_t = newX1[0][0]\nmem_good_t = newX1[0][1]\ncpu_bad_t = newX2[0][0]\nmem_bad_t = newX2[0][1]\n\n\n# Put the result into a color plot\n# Plot with training data set\nplt.title('Server Status')\nZ = Z.reshape(xx.shape)\nplt.xlim(xx.min(), xx.max())\nplt.ylim(yy.min(), yy.max())\nplt.pcolormesh(xx, yy, Z, cmap='Pastel2')\nplt.scatter(cpu_good, mem_good, color = \"g\", label=\"Train Good\")\nplt.scatter(cpu_bad, mem_bad, color = \"r\", label=\"Train Bad\")\nplt.scatter(cpu_good_t, mem_good_t, color = \"g\", marker = 'v', label=\"Test Good\")\nplt.scatter(cpu_bad_t, mem_bad_t, color = \"r\", marker = 'v', label=\"Test Bad\")\nplt.legend()\nplt.xlabel(\"CPU\")\nplt.ylabel(\"Memory\")\nplt.show()\n\n# Plot with testing data set\nplt.title('Server Status with Testing Data')\nplt.xlim(xx.min(), xx.max())\nplt.ylim(yy.min(), yy.max())\nplt.pcolormesh(xx, yy, Z, cmap='Pastel2', edgecolor='face')\nplt.scatter(cpu_good_t, mem_good_t, color = \"g\", marker = 'v', label=\"Good\")\nplt.scatter(cpu_bad_t, mem_bad_t, color = \"r\", marker = 'v', label=\"Bad\")\nplt.legend()\nplt.xlabel(\"CPU\")\nplt.ylabel(\"Memory\")\nplt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Training an algorithm (Naive Bayes) to predict server performance\n    - Generate data to simulation server performance (CPU, Memory -> Good or Bad)\n    - Split the data into a train set and a test set (3 to 1 ratio)\n    - Train Naive Bayes algorithm (A ML Classifier) with training data\n    - Predict server performance: good or bad using the remaining 25% of data\n    - Evaluate Model performance - calculate metrics such as recall, precision and accuracy\n## "]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["import numpy as np\nimport pylab as pl\nimport random\n\n# Generate data set\n# Seed the random number so that the result can be reproduced\nrandom.seed(42)\nn_points=1000\ncpu = [random.random() for ii in range(0,n_points)]\nmem = [random.random() for ii in range(0,n_points)]\nerror = [random.random() for ii in range(0,n_points)]\ny = [round(cpu[ii]*mem[ii]+0.3+0.1*error[ii]) for ii in range(0,n_points)]\nfor ii in range(0, len(y)):\n    if cpu[ii]>0.9 or mem[ii]>0.99:\n        y[ii] = 1.0\n\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["\n# split the data into train/test sets\n# Here we want 3/4 as train data and 1/4 as test data\nX = [[gg, ss] for gg, ss in zip(cpu, mem)]\nsplit = int(0.75*n_points)\nfeatures_train = X[0:split]\nfeatures_test  = X[split:]\nlabels_train = y[0:split]\nlabels_test  = y[split:]\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["\n# Use Naive Bayes classifier to model the problem\n# Here we are training \nfrom sklearn.naive_bayes import GaussianNB\nclf = GaussianNB()\nclf.fit(features_train, labels_train)\npred = clf.predict(features_test)\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["\n# One import aspect in ML modeling is to evaluate the model\n# Calculate accuracy\n# Accuracy = (true positive + true negative) / (total population)\naccuracy = clf.score(features_train, labels_train)\nprint 'Model accuracy with training data is ' + str(accuracy)\naccuracy = clf.score(features_test, labels_test)\nprint 'Model accuracy with testing data is ' + str(accuracy)\n\n# Produce confusion_matrix to calculate how good the model is in various aspects\nfrom sklearn.metrics import confusion_matrix\ncf = confusion_matrix(labels_test, pred)\nprint(\"\\nConfusion_matrics:\")\nprint(cf)\ntn, fp, fn, tp = cf.ravel()\nprint \"\\nTrue Negative = \" + str(tn)\nprint \"\\nFalse Positive = \" + str(fp)\nprint \"\\nFalse Negative = \" + str(fn)\nprint \"\\nTrue Positive = \" + str(tp)\n\n# Calculate precision, recall and f1-score\n# precision: tp / (tp + fp) => true alarm relative to all alarms\n# recall: tp / (tp + fn) => true alarm relative to all Bad condition\n# In this case, we are more concerned about missing alarms, thus we want high recall\n# f1-score: harmonic mean of precision and recall (2/(1/precision + 1/recall))\n# support: number of class label\n# avg: weighted average across all classes ( this is a binary class case) - sum(precision*support)/sum(support)\nfrom sklearn.metrics import classification_report\nprint(\"\\nClassification Report:\")\nprint(classification_report(labels_test, pred))\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# We want to visualize our results\n# decision bounday is the boundary seperating classes\n# draw the decision boundary with the text points overlaid\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport matplotlib\nimport matplotlib.pyplot as plt\n#matplotlib.pyplot.switch_backend('agg')\n\nx_min = 0.0; x_max = 1.0\ny_min = 0.0; y_max = 1.0\n\n# Plot the decision boundary. For that, we will assign a color to each\n# point in the mesh [x_min, m_max]x[y_min, y_max].\nh = .01  # step size in the mesh\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\nZ = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n\n# the training data (features_train, labels_train) have both \"Good\" and \"Bad\" points mixed\n# in together--separate them so we can give them different colors in the scatterplot,\n# and visually identify them\ncpu_good = [features_train[ii][0] for ii in range(0, len(features_train)) if labels_train[ii]==0]\nmem_good = [features_train[ii][1] for ii in range(0, len(features_train)) if labels_train[ii]==0]\ncpu_bad = [features_train[ii][0] for ii in range(0, len(features_train)) if labels_train[ii]==1]\nmem_bad = [features_train[ii][1] for ii in range(0, len(features_train)) if labels_train[ii]==1]\n\n# Plot also the test points\ncpu_good_t = [features_test[ii][0] for ii in range(0, len(features_test)) if labels_test[ii]==0]\nmem_good_t = [features_test[ii][1] for ii in range(0, len(features_test)) if labels_test[ii]==0]\ncpu_bad_t = [features_test[ii][0] for ii in range(0, len(features_test)) if labels_test[ii]==1]\nmem_bad_t = [features_test[ii][1] for ii in range(0, len(features_test)) if labels_test[ii]==1]\n\n\n# Put the result into a color plot\n# Plot with training data set\nplt.title('Server Performance with Training Data')\nZ = Z.reshape(xx.shape)\nplt.xlim(xx.min(), xx.max())\nplt.ylim(yy.min(), yy.max())\nplt.pcolormesh(xx, yy, Z, cmap='Pastel2')\nplt.scatter(cpu_good, mem_good, color = \"g\", label=\"Good\")\nplt.scatter(cpu_bad, mem_bad, color = \"r\", label=\"Bad\")\nplt.legend()\nplt.xlabel(\"CPU\")\nplt.ylabel(\"Memory\")\nplt.show()\n\n# Plot with testing data set\nplt.title('Server Performance with Testing Data')\nplt.xlim(xx.min(), xx.max())\nplt.ylim(yy.min(), yy.max())\nplt.pcolormesh(xx, yy, Z, cmap='Pastel2', edgecolor='face')\nplt.scatter(cpu_good_t, mem_good_t, color = \"g\", marker = 'v', label=\"Good\")\nplt.scatter(cpu_bad_t, mem_bad_t, color = \"r\", marker = 'v',  label=\"Bad\")\nplt.legend()\nplt.xlabel(\"CPU\")\nplt.ylabel(\"Memory\")\nplt.show()\n\n#plt.savefig(\"/opt/data/share01/jl2408/test.png\")\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## Training a SVM algorithm to predict server performance\n- Generate data to simulation server performance (CPU, Memory -> Good or Bad)\n- Split the data into a train set and a test set (3 to 1 ratio)\n- Train Support Vector Machine algorithm (A ML Classifier) with training data\n- Predict server performance: good or bad using the remaining 25% of data\n- Evaluate Model performance - calculate metrics such as recall, precision and accuracy\n## "]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["import numpy as np\nimport pylab as pl\nimport random\n\n# Generate data set\n# Seed the random number so that the result can be reproduced\nrandom.seed(42)\nn_points=1000\ncpu = [random.random() for ii in range(0,n_points)]\nmem = [random.random() for ii in range(0,n_points)]\nerror = [random.random() for ii in range(0,n_points)]\ny = [round(cpu[ii]*mem[ii]+0.3+0.1*error[ii]) for ii in range(0,n_points)]\nfor ii in range(0, len(y)):\n    if cpu[ii]>0.9 or mem[ii]>0.99:\n        y[ii] = 1.0\n\n# split into train/test sets\nX = [[gg, ss] for gg, ss in zip(cpu, mem)]\nsplit = int(0.75*n_points)\nfeatures_train = X[0:split]\nfeatures_test  = X[split:]\nlabels_train = y[0:split]\nlabels_test  = y[split:]\n\n# Use Support Vector Machine classifier to model the problem\n# Here we can tune the model with kernel, gamma and C\n# rbf: Radial Basis Function - a ML kernel\n# Data points contains pattern + stochastic noise. The goal of machine learning is to model the pattern and ignore the noise. Anytime an algorithm is trying to fit the noise in addition to the pattern, it is overfitting. Adjust gamma and C to avoid underfitting or overfitting\nfrom sklearn.svm import SVC\nclf = SVC(kernel='rbf', gamma = 1., C=10000.)\nclf.fit(features_train, labels_train)\npred = clf.predict(features_test)\n\n# Calculate accuracy\naccuracy = clf.score(features_train, labels_train)\nprint 'Model accuracy with training data is ' + str(accuracy)\naccuracy = clf.score(features_test, labels_test)\nprint 'Model accuracy with testing data is ' + str(accuracy)\n\n\n### draw the decision boundary with the text points overlaid\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport matplotlib\nimport matplotlib.pyplot as plt\n#matplotlib.pyplot.switch_backend('agg')\n\nx_min = 0.0; x_max = 1.0\ny_min = 0.0; y_max = 1.0\n\n# Plot the decision boundary. For that, we will assign a color to each\n# point in the mesh [x_min, m_max]x[y_min, y_max].\nh = .01  # step size in the mesh\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\nZ = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n\n# the training data (features_train, labels_train) have both \"Good\" and \"Bad\" points mixed\n# in together--separate them so we can give them different colors in the scatterplot,\n# and visually identify them\ncpu_good = [features_train[ii][0] for ii in range(0, len(features_train)) if labels_train[ii]==0]\nmem_good = [features_train[ii][1] for ii in range(0, len(features_train)) if labels_train[ii]==0]\ncpu_bad = [features_train[ii][0] for ii in range(0, len(features_train)) if labels_train[ii]==1]\nmem_bad = [features_train[ii][1] for ii in range(0, len(features_train)) if labels_train[ii]==1]\n\n# Plot also the test points\ncpu_good_t = [features_test[ii][0] for ii in range(0, len(features_test)) if labels_test[ii]==0]\nmem_good_t = [features_test[ii][1] for ii in range(0, len(features_test)) if labels_test[ii]==0]\ncpu_bad_t = [features_test[ii][0] for ii in range(0, len(features_test)) if labels_test[ii]==1]\nmem_bad_t = [features_test[ii][1] for ii in range(0, len(features_test)) if labels_test[ii]==1]\n\n\n# Put the result into a color plot\n# Plot with training data set\nplt.title('Server Performance with Training Data')\nZ = Z.reshape(xx.shape)\nplt.xlim(xx.min(), xx.max())\nplt.ylim(yy.min(), yy.max())\nplt.pcolormesh(xx, yy, Z, cmap='Pastel2')\nplt.scatter(cpu_good, mem_good, color = \"g\", label=\"Good\")\nplt.scatter(cpu_bad, mem_bad, color = \"r\", label=\"Bad\")\nplt.legend()\nplt.xlabel(\"CPU\")\nplt.ylabel(\"Memory\")\nplt.show()\n\n# Plot with testing data set\nplt.title('Server Performance with Testing Data')\nplt.xlim(xx.min(), xx.max())\nplt.ylim(yy.min(), yy.max())\nplt.pcolormesh(xx, yy, Z, cmap='Pastel2', edgecolor='face')\nplt.scatter(cpu_good_t, mem_good_t, color = \"g\", marker = 'v', label=\"Good\")\nplt.scatter(cpu_bad_t, mem_bad_t, color = \"r\", marker = 'v',  label=\"Bad\")\nplt.legend()\nplt.xlabel(\"CPU\")\nplt.ylabel(\"Memory\")\nplt.show()\n\n#plt.savefig(\"/opt/data/share01/jl2408/test.png\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.1"}},"nbformat":4,"nbformat_minor":2}
