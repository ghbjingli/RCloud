{"cells":[{"cell_type":"markdown","metadata":{},"source":["## *Table of Contents*\n\n    * Cars Data Cleaning\n    * Load Data and Get Directory Path\n    * Resolve Basic Issues\n    * Model and SubModel Variables\n    * Remove Variables/Observations\n    * Impute Missing Values\n    * Split Data\n    * Demo Signup & Prep\n    * Next Steps\n\n \n## *Cars Data Cleaning*\n\nFor your final project you will be working on a Kaggle challenge data set called cars. The goal of the challenge is to predict whether a used car at an auto auction is a good or bad buy. This is done using the following variables to predict the binary IsBadBuy variable.\n\n*Field Name:\tDefinition*\n\nRefID:\tUnique (sequential) number assigned to vehicles\nIsBadBuy:\tIdentifies if the kicked vehicle was an avoidable purchase\nPurchDate:\tThe Date the vehicle was Purchased at Auction\nAuction:\tAuction provider at which the vehicle was purchased\nVehYear:\tThe manufacturer’s year of the vehicle\nVehicleAge:\tThe Years elapsed since the manufacturer’s year\nMake:\tVehicle Manufacturer\nModel:\tVehicle Model\nTrim:\tVehicle Trim Level\nSubModel:\tVehicle Submodel\nColor:\tVehicle Color\nTransmission:\tVehicles transmission type (Automatic, Manual)\nWheelTypeID:\tThe type id of the vehicle wheel\nWheelType:\tThe vehicle wheel type description (Alloy, Covers)\nVehOdo:\tThe vehicles odometer reading\nNationality:\tThe Manufacturer’s country\nSize:\tThe size category of the vehicle (Compact, SUV, etc.)\nTopThreeAmericanName:\tIdentifies if the manufacturer is one of the top three American manufacturers\nMMRAcquisitionAuctionAveragePrice:\tAcquisition price for this vehicle in average condition at time of purchase\nMMRAcquisitionAuctionCleanPrice:\tAcquisition price for this vehicle in the above Average condition at time of purchase\nMMRAcquisitionRetailAveragePrice:\tAcquisition price for this vehicle in the retail market in average condition at time of purchase\nMMRAcquisitonRetailCleanPrice:\tAcquisition price for this vehicle in the retail market in above average condition at time of purchase\nMMRCurrentAuctionAveragePrice:\tAcquisition price for this vehicle in average condition as of current day\nMMRCurrentAuctionCleanPrice:\tAcquisition price for this vehicle in the above condition as of current day\nMMRCurrentRetailAveragePrice:\tAcquisition price for this vehicle in the retail market in average condition as of current day\nMMRCurrentRetailCleanPrice:\tAcquisition price for this vehicle in the retail market in above average condition as of current day\nPRIMEUNIT:\tIdentifies if the vehicle would have a higher demand than a standard purchase\nAcquisitionType:\tIdentifies how the vehicle was acquired (Auction buy, trade in, etc)\nAUCGUART:\tThe level guarantee provided by auction for the vehicle (Green light - Guaranteed/arbitratable, Yellow Light - caution/issue, red light - sold as is)\nKickDate:\tDate the vehicle was kicked back to the auction\nBYRNO:\tUnique number assigned to the buyer that purchased the vehicle\nVNZIP:\tZipcode where the car was purchased\nVNST:\tState where the the car was purchased\nVehBCost:\tAcquisition cost paid for the vehicle at time of purchase\nIsOnlineSale:\tIdentifies if the vehicle was originally purchased online\nWarrantyCost:\tWarranty price (term=36month and millage=36K)\n\n## *Load Data and Get Directory Path*\n\nNote: The following is a general guide in attacking this problem, feel free to approach the data cleaning process in other ways. However, keep in mind many of general goals in this guide have to be performed in some manner before a logistic regression can be performed and/or trusted.\n\nThe first thing you must do is load the data into RCloud using the File Upload GUI.  The file is now in your home directory on RCloud.  The path to your file can be seen in absolute terms by running \"list.files(rcloud.home(), full.names=TRUE\". However, it is good practice to use \"rcloud.home()\" to specify the path to your file rather than using absolute paths.  You may also create directories using R - dir.create(\"cars\"), move files to that directory using file.rename(from=\"rcloud.home()\", to=\"rcloud.home(\"cars\") or using an RCloud shell cell and the commands\n\nmv /opt/data/share01/yourID/filename /opt/data/share01/cars\n\nand then access files in that directory using rcloud.home(\"cars\"); note you can create directories with any name, not just cars.\n\nNote: The test data set provided by the website is optional for this assignment. We will be performing all of our work solely on the training data set. Feel free to run your final model on the cleaned (by you) test data set and submit it to Kaggle to see how well your model does against others submitted to the competition.\n\n## *Resolve Basic Issues*\n\nNext, examine the data and fix basic issues. Items such as dropping variables that are obviously of no use or fixing things such as miss coded values. At this point I dropped the PurchDate variable due to not wanting to deal with date variables. However, if you are up to the challenge feel free to leave it in and attack the problem. It should be noted though that you will not able to just throw it into a logistic regression raw. That will leave you with too many levels which is an issue we will discuss in further detail later. However, it can be used in a logistic regression in terms of months or years and the raw data can be useful in the exploratory analysis phase.\n\n```{R}\n#corrects zero values to NA for certain variables\n#cars_train[,c(18:25)] <-apply(cars_train[,c(18:25)], 2, function(x) x <-ifelse(x == 0, NA, x))\n```\n\n \n## *Model and SubModel Variables*\n\nNext we need to deal with Model and SubModel variables. There are two major goals we want to achieve in this section. We want to extract information contained in the model names. For simplicity, you only have to extract the number of doors from the SubModel variable. However, feel free to extract other pieces of information if you like. Though, be aware, most of the other pieces of information contained in the model variables are too spotty to make up a variable of their own.\n\nHint: The grep function could be a useful function here.\n\n \n\nThe second goal we want to achieve is a reduction in the number of levels in the models. In this case there are 863 levels in submodel and 1063 levels in the model. This leads to over-parameterization (a saturated model) which causes NAs to start showing up in the regression due to lack of variance for estimating the parameters. There are several ways to attack this problem, I used a hands on approach to group levels. However, you can do a similar thing with more advance statistical techniques such as k-means. Feel free to approach the problem in any way you see fit.\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\t\n#reduces the number of model levels\ncars_train$NewModel <-sapply(strsplit(as.character(cars_train$Model), ' '), \"[[\", 1)\ncars_train$NewModel[grep(\"1500 Ram\", cars_train$Model , ignore.case=TRUE, fixed=FALSE)] <-\"Ram\"\ncars_train$NewModel[c(grep(\"1500 Silverado\", cars_train$Model , ignore.case=TRUE, fixed=FALSE),\n                      grep(\"1500HD Silverado\", cars_train$Model , ignore.case=TRUE, fixed=FALSE))] <-\"Silverado\"\ncars_train$NewModel[grep(\"1500 Sierra\", cars_train$Model , ignore.case=TRUE, fixed=FALSE)] <-\"Sierra\"\ncars_train$NewModel[grep(\"4 Runner\", cars_train$Model , ignore.case=TRUE, fixed=FALSE)] <-\"4 Runner\"\ncars_train$NewModel[grep(\"L Series\", cars_train$Model , ignore.case=TRUE, fixed=FALSE)] <-\"L Series\"\ncars_train$NewModel <-as.factor(cars_train$NewModel)\n\n \n\n \nRemove Variables/Observations\n\nThe last thing you need to do before imputation is to remove variables and observations with too many missing values. Imputation can be a wonderful tool, but beyond a certain number of missing you start to weight the variable/observation too heavily with the imputed values thus guaranteeing a result based upon how we imputed. This leaves the question of how much is too much? I can’t really answer that for you. However, I can say you generally don’t want to impute if more than 50% is missing and you generally wouldn’t even go that far with less advanced statistical techniques such as the basic one that will be used below.\n1\n2\n\t\n#check to see how many observations are missing in each variable then null (removes) those with too many\nmiss_obs_per_var <-apply(cars_train, 2, function(x) sum(is.na(x))/length(x)*100)\n\n \n\nBefore we impute, feel free to do anything else you feel needs to be done in the data cleaning process. What we have done is by no means all that can be done, nor even all that should be done. Don’t forget, this is a general guideline; statistics is not easily made into an algorithm. If it was, I might not have a job.\n\n \nImpute Missing Values\n\nNow we can impute the missing values. This can be done using the random.imp function found in the mi library. The random.imp function randomly imputes the missing values using the distribution of the variables in which the missing values are found. There are many other imputation methods and approaches. Feel free to try out and use other methods (I’m partial to multiple imputation also found in the mi library myself). More information on imputation can be found here.\n\n \n1\n2\n3\n\t\n#Randomly imputes based upon the distribution of the variable.\nlibrary(mi)\ncars_train_imp <-random.imp(cars_train)\n\n \nSplit Data\n\nFinally we will split the data into test and training sets. There are several methods and philosophies around doing this; however, the general rule is as follows: if you have enough data, you split it by putting 40% into 1 training data set and 20% each into 3 test data sets.\n\n \nDemo Signup & Prep\n\n It’s time to schedule your demo! This is about the halfway point for the iteration, the perfect time to get signed up so we can ensure your demo will take place during the demo week set aside for your group.\n\n \n\nPlease follow the steps below before continuing with the iteration:\n\n    Review the demo help guide. It has additional info on scheduling and tips to be successful in your demo.\n    Find your Topic Advisor. Please note that Topic Advisors can change with each iteration due to resource needs. Be in the habit of checking your Topic Advisor each time you schedule demos.\n        Go to your OLE Study Group.\n        In the Milestones section, click on the task for the current iteration demo week (see Example 1 below).\n        The task will expand to show a description where the Topic Advisor’s name and ID are listed.\n    Send Outlook invite\n        Access the Topic Advisor’s calendar in Outlook. Their calendar is public, so you should be able to access. If you have any issues please engage the Topic Advisor.\n        There will be blocks of time set aside each day for demos\n        Find a day and time that is available within those blocks and that works with your schedule (see Example 2 below).\n        Send an invite for a 30 minute meeting to the Topic Advisor.\n        The Topic Advisor will accept the invite and you are now scheduled!\n    Demo prep\n        Start creating a document (PowerPoint, Word, OneNote, etc.) for use during your demo.\n        This will be used to help show the Topic Advisor how you progressed through the iteration.\n        Think about adding screen shots or plan on live demos to help supplement the document and demonstrate your learnings.\n        Update the document as you move through the last week of the iteration."]},{"cell_type":"markdown","metadata":{},"source":["Load training data into R\n```{R}\nlist.files(rcloud.home(), full.names=TRUE)\ncars_train <- read.csv(rcloud.home(\"training.csv\", user=\"jl2408\"), sep=\",\", header = T, check.names = F)\n"]},{"cell_type":"markdown","metadata":{},"source":["Explore the data\n```{R}\nstr(cars_train)\nsummary(cars_train)"]},{"cell_type":"markdown","metadata":{},"source":["How many cars are bad buy?\n```{R}\ntable(cars_train$IsBadBuy)"]},{"cell_type":"markdown","metadata":{},"source":["```{R}\n# drop column PurchDate\ncars_train <- subset(cars_train, select = -c(PurchDate))\n\n# convert factor into numeric\n#cars_train[,c(18:25)] <- #as.numeric(levels(cars_train[,c(18:25)]))[cars_train[,c(18:25)]]\n\n\n#corrects zero values to NA for certain variables\ncars_train[,c(18:25)] <-apply(cars_train[,c(18:25)], 2, function(x) x <-ifelse(x == 0, NA, x))\nstr(cars_train)\n```"]},{"cell_type":"markdown","metadata":{},"source":["```{R}\nlevels(cars_train$PRIMEUNIT)\nlevels(cars_train$AUCGUART)\ntable(cars_train$PRIMEUNIT)\ntable(cars_train$AUCGUART)\n\n# drop column these 2 columns\ncars_train <- subset(cars_train, select = -c(PRIMEUNIT,AUCGUART))"]},{"cell_type":"markdown","metadata":{},"source":["```{R}\n# apply(cars_train, 2, function (x) any(is.na(x)))\n\n# apply(cars_train, 2, function (x) any(is.infinite(x)))\n\n#check to see how many observations are missing in each variable then null (removes) those with too many\n\nmiss_obs_per_var <-apply(cars_train, 2, function(x) sum(is.na(x))/length(x)*100)\nmiss_obs_per_var\n\nnull_obs_per_var <-apply(cars_train, 2, function(x) sum(is.null(x))/length(x)*100)\nnull_obs_per_var\n\nlibrary(Amelia)\nmissmap(cars_train, main = \"Missing values vs observed\")"]},{"cell_type":"markdown","metadata":{},"source":["```{R}\n# Randomly imputes based upon the distribution of the variable.\n\n\nrandom.imp <- function ( data , imp.method = c( \"bootstrap\", \"pca\" ) , ... ) {\n\n  imp.method <- match.arg ( imp.method )\n\n  if(imp.method==\"bootstrap\"){\n\n    if( is.vector( data ) ) {\n\n      mis       <- is.na ( data )\n\n      imputed   <- data\n\n      imputed[ mis ] <- sample( data[ !mis ], sum( mis ), replace = TRUE )\n\n    }\n\n    else if( is.matrix( data ) || is.data.frame( data )  ){\n\n      imputed <- data\n\n      for( j in 1:ncol ( data ) ) {\n\n        mis  <- is.na ( data[,j] )\n\n        if( sum(mis) == length(data[,j])){\n\n          warning(message = paste( \"variable\", names(data)[j], \"has no observation\"))\n\n        }\n\n        else {\n\n          imputed[mis,j] <- sample( data[!mis, j], sum( mis ), replace = TRUE )\n\n        }\n\n      }\n\n    }\n\n    else{\n\n      stop ( message = \"Unexpected data type: data must be vector, matrix, or data frame.\" )\n\n    }\n\n  }\n\n  else if (imp.method==\"pca\"){\n\n    stop ( message = \"pca imputation is not implemente in current version.\" )\n\n  }\n\n  \n\n  #else{\n\n  #    imputed <- pca( data, nPcs = 3, method = \"bpca\" )@completeObs\n\n  #}\n\n  return( as.data.frame( imputed ) )\n\n}\n\n\ncars_train_imp <-random.imp(cars_train)\n\n```\n\n# Replace missing vallue with the average\n\ncars_train$MMRAcquisitionAuctionAveragePrice[is.na(cars_train$MMRAcquisitionAuctionAveragePrice)] <- round(mean(as.numeric(cars_train$MMRAcquisitionAuctionAveragePrice),na.rm=T))\n#cars_train$MMRAcquisitionAuctionAveragePrice\ncars_train$MMRAcquisitionAuctionAveragePrice <- as.factor(cars_train$MMRAcquisitionAuctionAveragePrice)\n\ncars_train$MMRAcquisitionAuctionCleanPrice[is.na(cars_train$MMRAcquisitionAuctionCleanPrice)] <- round(mean(as.numeric(cars_train$MMRAcquisitionAuctionCleanPrice),na.rm=T))\n#cars_train$MMRAcquisitionAuctionCleanPrice\ncars_train$MMRAcquisitionAuctionCleanPrice <- as.factor(cars_train$MMRAcquisitionAuctionCleanPrice)\n\ncars_train$MMRAcquisitionRetailAveragePrice[is.na(cars_train$MMRAcquisitionRetailAveragePrice)] <- round(mean(as.numeric(cars_train$MMRAcquisitionRetailAveragePrice),na.rm=T))\n#cars_train$MMRAcquisitionRetailAveragePrice\ncars_train$MMRAcquisitionRetailAveragePrice <- as.factor(cars_train$MMRAcquisitionRetailAveragePrice)\n\ncars_train$MMRAcquisitionRetailCleanPrice[is.na(cars_train$MMRAcquisitionRetailCleanPrice)] <-\nround(mean(as.numeric(cars_train$MMRAcquisitionRetailCleanPrice),na.rm=T))\n#cars_train$MMRAcquisitionRetailCleanPrice\ncars_train$MMRAcquisitionRetailCleanPrice <- as.factor(cars_train$MMRAcquisitionRetailCleanPrice)\n\ncars_train$MMRCurrentAuctionAveragePrice[is.na(cars_train$MMRCurrentAuctionAveragePrice)] <- round(mean(as.numeric(cars_train$MMRCurrentAuctionAveragePrice),na.rm=T))\n#cars_train$MMRCurrentAuctionAveragePrice\ncars_train$MMRCurrentAuctionAveragePrice <- as.factor(cars_train$MMRCurrentAuctionAveragePrice)\n\ncars_train$MMRCurrentAuctionCleanPrice[is.na(cars_train$MMRCurrentAuctionCleanPrice)] <- round(mean(as.numeric(cars_train$MMRCurrentAuctionCleanPrice),na.rm=T))\n#cars_train$MMRCurrentAuctionCleanPrice\ncars_train$MMRCurrentAuctionCleanPrice <- as.factor(cars_train$MMRCurrentAuctionCleanPrice)\n\ncars_train$MMRCurrentRetailAveragePrice[is.na(cars_train$MMRCurrentRetailAveragePrice)] <- round(mean(as.numeric(cars_train$MMRCurrentRetailAveragePrice),na.rm=T))\n#cars_train$MMRCurrentRetailAveragePrice\ncars_train$MMRCurrentRetailAveragePrice <- as.factor(cars_train$MMRCurrentRetailAveragePrice)\n\ncars_train$MMRCurrentRetailCleanPrice[is.na(cars_train$MMRCurrentRetailCleanPrice)] <- round(mean(as.numeric(cars_train$MMRCurrentRetailCleanPrice),na.rm=T))\n#cars_train$MMRCurrentRetailCleanPrice\ncars_train$MMRCurrentRetailCleanPrice <- as.factor(cars_train$MMRCurrentRetailCleanPrice)\n"]},{"cell_type":"markdown","metadata":{},"source":["Check what is in Model\n```{R}\nt <- cars_train$Model\nhead(t, 20)\nlength(levels(t))\nt2 <- as.factor(sapply(strsplit(as.character(t), ' '), \"[[\", 1))\nlevels(t2)\nlength(levels(t2))\n#t[grep(\"^[0-9]+\", t , ignore.case=TRUE, fixed=FALSE)]\nt[grep(\"^25+\", t , ignore.case=TRUE, fixed=FALSE)]"]},{"cell_type":"markdown","metadata":{},"source":["Check what is in SubModel\n```{R}\nt <- cars_train$SubModel\nhead(t, 20)\nlength(levels(t))\nt2 <- as.factor(sapply(strsplit(as.character(t), ' '), \"[[\", 1))\nlevels(t2)\nlength(levels(t2))"]},{"cell_type":"markdown","metadata":{},"source":["```{R}\n# reduces the number of model levels\ncars_train$Model <- as.character(cars_train$Model)\ncars_train$Model[grep(\"1500 Ram\", cars_train$Model , ignore.case=TRUE, fixed=FALSE)] <-\"Ram\"\ncars_train$Model[c(grep(\"1500 Silverado\", cars_train$Model , ignore.case=TRUE, fixed=FALSE),\n                      grep(\"1500HD Silverado\", cars_train$Model , ignore.case=TRUE, fixed=FALSE))] <-\"Silverado\"\ncars_train$Model[grep(\"1500 Sierra\", cars_train$Model , ignore.case=TRUE, fixed=FALSE)] <-\"Sierra\"\ncars_train$Model[grep(\"4 Runner\", cars_train$Model , ignore.case=TRUE, fixed=FALSE)] <-\"4_Runner\"\ncars_train$Model[grep(\"L Series\", cars_train$Model , ignore.case=TRUE, fixed=FALSE)] <-\"L_Series\"\ncars_train$Model <-sapply(strsplit(as.character(cars_train$Model), ' '), \"[[\", 1)\ncars_train$Model <-as.factor(cars_train$Model)\n\nlength(levels(cars_train$Model))\n```"]},{"cell_type":"markdown","metadata":{},"source":["```{R}\n# reduces the number of submodel levels\ncars_train$SubModel <- as.character(cars_train$SubModel)\ncars_train$SubModel <-sapply(strsplit(as.character(cars_train$SubModel), ' '), \"[[\", 1)\ncars_train$SubModel <-as.factor(cars_train$SubModel)\n\nlength(levels(cars_train$SubModel))\n```"]},{"cell_type":"markdown","metadata":{},"source":["````{R}\n# Split Data\n# when using a random number, it's usually a good idea to set the seed. This\n# guarantees your results are repeatable.\n \nset.seed(100)\n \n# first we create an index on all the rows in the cars_train dataset\nindex <- 1:nrow(cars_train)\n \n# this command randomly samples 40% of the index numbers \ntestindex <- sample(index, trunc(length(index)/1.5))\n \n# all the index numbers not in the sample become part of our training set.\ncars.trainset <- cars_train[-testindex, ]\n \n# the rest go into our test set.\ncars.testset <- cars_train[testindex, ]\n\n# further split test set into 3\n# first we create an index on all the rows in the cars.testset dataset\nindex <- 1:nrow(cars.testset)\n\n# this command randomly samples 1/3 of the index numbers \ntestindex <- sample(index, trunc(length(index)/3))\n\n# the first test set.\ncars.testset1 <- cars.testset[testindex, ]\n\n# the rest goes to car.testset.tmp\ncars.testset.tmp <- cars.testset[-testindex, ]\n\n# further split testset.tmp set into 2\n# first we create an index on all the rows in the cars.testset dataset\nindex <- 1:nrow(cars.testset.tmp)\n\n# this command randomly samples 1/2 of the index numbers \ntestindex <- sample(index, trunc(length(index)/2))\n\n# the first test set.\ncars.testset2 <- cars.testset.tmp[testindex, ]\n\n# the rest goes to car.testset.tmp\ncars.testset3 <- cars.testset.tmp[-testindex, ]\n\n\nstr(cars.trainset)\nstr(cars.testset1)\nstr(cars.testset2)\nstr(cars.testset3)"]},{"cell_type":"markdown","metadata":{},"source":["```{R}\n\ntable(cars.testset1$IsBadBuy)\ntable(cars.testset1$TopThreeAmericanName)\ntable(cars_train$TopThreeAmericanName)\n# cars.model = glm(IsBadBuy ~ Auction + VehYear + VehicleAge + Make + Model + Trim + SubModel + Color + Transmission + WheelTypeID + WheelType + VehOdo + Nationality + Size + TopThreeAmericanName + MMRAcquisitionAuctionAveragePrice + MMRAcquisitionAuctionCleanPrice + MMRAcquisitionRetailAveragePrice + MMRAcquisitionRetailCleanPrice + MMRCurrentAuctionAveragePrice + MMRCurrentAuctionCleanPrice + MMRCurrentRetailAveragePrice + MMRCurrentRetailCleanPrice + BYRNO + VNZIP1 + VNST + VehBCost + IsOnlineSale + WarrantyCost, family=binomial(logit), data=cars.trainset)\n\n# cars.model = glm(IsBadBuy ~ Auction + VehYear + VehicleAge + Make + Model + Trim + SubModel + WheelType + VehOdo + Size + MMRAcquisitionAuctionAveragePrice + MMRAcquisitionAuctionCleanPrice + MMRAcquisitionRetailAveragePrice + MMRAcquisitionRetailCleanPrice + MMRCurrentAuctionAveragePrice + MMRCurrentAuctionCleanPrice + MMRCurrentRetailAveragePrice + MMRCurrentRetailCleanPrice + BYRNO + VNZIP1 + VehBCost + WarrantyCost, family=binomial(logit), data=cars.trainset)\n\n# cars.model = glm(IsBadBuy ~ VehYear + VehicleAge + Make + Model + SubModel + VehOdo + Size + MMRAcquisitionAuctionCleanPrice + VehBCost, family=binomial(logit), data=cars.trainset)\n\n# cars.model = glm(IsBadBuy ~ VehicleAge + Make + Model + VehOdo + Size + VehBCost, family=binomial(logit), data=cars.trainset)\n\ncars.model = glm(IsBadBuy ~ VehicleAge + VehOdo + VehBCost + MMRCurrentAuctionCleanPrice + MMRCurrentRetailAveragePrice + WarrantyCost, family=binomial(logit), data=cars.trainset)\n\nsummary(cars.model)\np <- predict(cars.model, cars.testset1, type='response')\n\n# create a new reference to the cars test data\nmy.cars<-cars.testset1\n# if p > 0.5, we're predicting the car is a bad buy\nmy.cars$predicted.IsBadBuy <- p>0.1\n# the table command allows us to see how ofter our predictions were accurate.\ntable(my.cars$IsBadBuy,my.cars$predicted.IsBadBuy)"]},{"cell_type":"markdown","metadata":{},"source":["```{R}\nlibrary(psychometric)\nCIr(r=0.376, n = 61, level=.95)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.1"}},"nbformat":4,"nbformat_minor":2}
